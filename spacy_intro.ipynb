{"cells":[{"cell_type":"markdown","source":"# Wprowadzenie do biblioteki spaCy\n\nspaCy to biblioteka służąca do Przetwarzania Języka Naturalnego (ang. _NLP - Natural Language Processing_).\nJej pełna dokumentacja techniczna, wraz z dużą ilością dodatków oraz samouczków znajduje się na stronie: https://spacy.io/","metadata":{"tags":[],"cell_id":"0e3b4e4d-4968-4bab-8fe9-ae7b8878fb56"}},{"cell_type":"markdown","source":"## Instalacja biblioteki\n\nProgramując w Pythonie często korzystamy z różnego rodzaju gotowych bibliotek (lub tzw. pakietów), które możemy instalować za pomocą komendy `pip install __nazwa_pakietu__` __Terminala__ lub bezpośrednio w komórce notatnika, poprzedzając w/w instrukcję wykrzyknikiem: `!`\n","metadata":{"cell_id":"411ee703-f352-45e9-814c-76bbd1a5af3c"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f279bb2a-57e9-4d6c-b2e4-902438b54299"},"source":"# Instalacja biblioteki spaCy\n!pip install spacy","outputs":[{"name":"stdout","text":"Collecting spacy\n  Using cached spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\nCollecting wasabi<1.1.0,>=0.4.0\n  Downloading wasabi-0.6.0-py3-none-any.whl (20 kB)\nCollecting srsly<1.1.0,>=1.0.2\n  Downloading srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)\n\u001b[K     |████████████████████████████████| 185 kB 5.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (1.18.4)\nCollecting catalogue<1.1.0,>=0.0.7\n  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\nCollecting plac<1.2.0,>=0.9.6\n  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\nCollecting preshed<3.1.0,>=3.0.2\n  Downloading preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118 kB)\n\u001b[K     |████████████████████████████████| 118 kB 5.7 MB/s eta 0:00:01\n\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n  Downloading cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)\nCollecting murmurhash<1.1.0,>=0.28.0\n  Downloading murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)\nCollecting thinc==7.4.0\n  Downloading thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n\u001b[K     |████████████████████████████████| 2.2 MB 5.3 MB/s eta 0:00:01     |███████████                     | 757 kB 5.3 MB/s eta 0:00:01     |█████████████████████           | 1.4 MB 5.3 MB/s eta 0:00:01     |████████████████████████        | 1.6 MB 5.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/venv/lib/python3.7/site-packages (from spacy) (2.23.0)\nRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from spacy) (46.4.0)\nCollecting tqdm<5.0.0,>=4.38.0\n  Downloading tqdm-4.46.0-py2.py3-none-any.whl (63 kB)\n\u001b[K     |████████████████████████████████| 63 kB 462 kB/s eta 0:00:01\n\u001b[?25hCollecting blis<0.5.0,>=0.4.0\n  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n\u001b[K     |████████████████████████████████| 3.7 MB 13.7 MB/s eta 0:00:01     |███████▏                        | 829 kB 13.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\nInstalling collected packages: wasabi, srsly, catalogue, plac, cymem, murmurhash, preshed, tqdm, blis, thinc, spacy\nSuccessfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 tqdm-4.46.0 wasabi-0.6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Aby móc korzystać z zainstalowanych pakietów należy je każdorazowo importować za pomocą instrukcji `import`:","metadata":{"tags":[],"cell_id":"57e54210-86e7-4e4e-89b2-e12de27e2bbb"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d330bc7f-0840-4e12-b018-66ccfc9bc432"},"source":"import spacy","outputs":[]},{"cell_type":"markdown","source":"## Modele językowe\n\nspaCy natywnie obsługuje kilkanaście pretrenowanych (!) modeli języka, są to:\n* Angielski\n* Niemiecki\n* Francuski\n* Hiszpański\n* Portugalski\n* Włoski\n* Holenderski\n* Grecki\n* Norweski\n* Bokmål\n* Litewski","metadata":{"tags":[],"cell_id":"fd1a7b76-8275-4c84-886e-12f351fe17bf"}},{"cell_type":"markdown","source":"Obiekt `nlp`","metadata":{"tags":[],"cell_id":"3d976d06-c1de-47a7-9e9e-c315f6bc29eb"}},{"cell_type":"markdown","source":"Najważniejszym obiektem, z którego będziemy korzystać w bibliotece spaCy jest obiekt zawierający _potok przetwarzania_ (ang. _pipeline_). Zwykle nazywamy tę zmienną `nlp`.\nNa przykład, aby utworzyć obiekt nlp w języku angielskim, musisz zaimportować klasę `English` ze `spacy.lang.en` i zainicjować ją, właśnie poprzez stworzenie zmiennej `nlp`.","metadata":{"tags":[],"cell_id":"90e1bbc3-7721-44f4-b088-54e3db1e63f4"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"dc6ab713-3e6f-47db-9d89-9298bbd4c213"},"source":"# Import klasy English\nfrom spacy.lang.en import English\n# Inicjacja klasy poprzez stworzenie zmiennej 'nlp'\nnlp = English()","outputs":[]},{"cell_type":"markdown","source":"Pod nazwą zmiennej `nlp` przechowywany jest najbardziej podstawowy składnik każdego kodu pisanego w Pythonie, czyli __obiekt__.\nObiekt `nlp`, zawiera:\n\n* potok przetwarzania\n* specyficzne dla języka zasady dotyczące np. tokenizacji (dzielenia tekstu na segmenty, czyli tzw. __tokeny__), lematyzacji (sprowadzania wszystkich słów do ich form bazowych, tzw. __lematów__)\n\nAby sprawdzić listę __atrybutów__ i __metod__ dowolnego obiektu w Pythonie, posłuż się funkcją `dir()`","metadata":{"tags":[],"cell_id":"2b6d8611-2534-4bf6-9fd5-fe42beae2468"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"def2685a-7e64-46e5-97a4-da2a9a5f0793"},"source":"dir(nlp)","outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"['Defaults',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_format_docs_and_golds',\n '_meta',\n '_multiprocessing_pipe',\n '_optimizer',\n '_path',\n 'add_pipe',\n 'begin_training',\n 'create_pipe',\n 'disable_pipes',\n 'entity',\n 'evaluate',\n 'factories',\n 'from_bytes',\n 'from_disk',\n 'get_pipe',\n 'has_pipe',\n 'lang',\n 'linker',\n 'make_doc',\n 'matcher',\n 'max_length',\n 'meta',\n 'parser',\n 'path',\n 'pipe',\n 'pipe_factories',\n 'pipe_labels',\n 'pipe_names',\n 'pipeline',\n 'preprocess_gold',\n 'rehearse',\n 'remove_pipe',\n 'rename_pipe',\n 'replace_pipe',\n 'resume_training',\n 'tagger',\n 'tensorizer',\n 'to_bytes',\n 'to_disk',\n 'tokenizer',\n 'update',\n 'use_params',\n 'vocab']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Obiekt `Doc`\n\n\nPodczas przetwarzania tekstu za pomocą obiektu nlp spaCy tworzy obiekt `Doc` - skrót od „dokument”. Dokument umożliwia dostęp do informacji o tekście w uporządkowany sposób.\n`Doc` zachowuje się jak normalny obiekt sekwencjy Pythona (np. lista) i pozwala iterować po swoich tokenach lub uzyskać token według jego indeksu. Ale więcej o tym później!","metadata":{"tags":[],"cell_id":"1bbc9c0d-16ff-4312-b5b6-2d651ed9c06a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"242a9073-2c00-4f28-81cf-845c8470d476"},"source":"# Tworzenie obiektu 'doc' dla dowolnego tekstu w języku angielskim\ndoc = nlp(\"Hello world!\")\n\n# iteracja po tokenach\nfor token in doc:\n    print(token.text)","outputs":[{"name":"stdout","text":"Hello\nworld\n!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Obiekty `token` reprezentują __tokeny__ w dokumencie - na przykład słowo lub znak interpunkcyjny.","metadata":{"tags":[],"cell_id":"9fecf816-d56f-439e-8aee-c8324ecd945a"}},{"cell_type":"markdown","source":"![tokeny](images/doc.png)","metadata":{"tags":[],"cell_id":"d4026407-029e-4c70-b1a6-a58a8073cdc3"}},{"cell_type":"markdown","source":"Aby uzyskać token w określonej pozycji, możesz korzystać z indeksowania tak samo jak w przypadku list, czyli za pomocą nawiasów kwadratowych `[]`, w których podajesz pozycję, w której znajduje się interesujące Cię słowo (w Pythonie indeksujemy od zera!)","metadata":{"tags":[],"cell_id":"8d21c879-9377-4beb-82d6-35776310a0fd"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2eb6b6d7-3e51-493d-a8f7-70fdd93ff5fd"},"source":"token = doc[1]\nprint(token)","outputs":[{"name":"stdout","text":"world\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Obiekty token `token` posiadają również różne atrybuty, które umożliwiają dostęp do dodatkowych informacji o tokenach. Na przykład atrybut `.text` zwraca pełny tekst tokenu.","metadata":{"tags":[],"cell_id":"ae7d5c75-7427-43f5-a1eb-7b5d75ad081c"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0abecade-8ccb-4760-9a3c-0302c7080146"},"source":"print(token.text)","outputs":[{"name":"stdout","text":"world\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Obiekt `span`","metadata":{"tags":[],"cell_id":"28c0d3ae-03e6-4b58-ad07-f4d27d4d3495"}},{"cell_type":"markdown","source":"Obiekt `span` to wycinek dokumentu składający się z jednego lub więcej tokenów. To tylko widok Dokumentu i nie zawiera żadnych danych.","metadata":{"tags":[],"cell_id":"3bd47a56-6d67-4dd1-9a28-09821a3e838a"}},{"cell_type":"markdown","source":"![Span](images/doc_span.png)","metadata":{"tags":[],"cell_id":"857f8322-5388-420a-a43d-ad45c0bdc899"}},{"cell_type":"markdown","source":"Aby utworzyć obiekt `span`, możesz użyć notacji _wycinka_ Pythona. Na przykład `[1:3]` utworzy wycinek, zaczynając od tokena na pozycji 1, aż do - ale nie wliczając! - tokena na pozycji 3.","metadata":{"tags":[],"cell_id":"d4411bdd-a9c6-4e11-9792-3525bad6c7fc"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d1c108b5-7d7b-46c2-9e45-08ccf4e4979c"},"source":"doc = nlp(\"Hello world!\")\nspan = doc[1:3]\nprint(span.text)","outputs":[{"name":"stdout","text":"world!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Atrybuty leksykalne","metadata":{"tags":[],"cell_id":"1154b113-cc21-46ec-89c5-9185e3b099c3"}},{"cell_type":"markdown","source":"Oto niektóre z dostępnych atrybutów dla tokenów:\n* `i` jest indeksem (numerem pozycji) tokena w dokumencie nadrzędnym.\n* `text` zwraca napis przyporządkowany do tokena\n* `is_alpha`, `is_punct` i `like_num` zwracają wartości logiczne wskazujące, czy token składa się ze znaków alfabetycznych (liter), czy to znak interpunkcyjny, czy też przypomina liczbę, np. token „10” - jeden, zero - lub słowo „ten” (\"dziesięć\").\n\nTe atrybuty są również nazywane __atrybutami leksykalnymi__: odnoszą się do pozycji w słowniku i nie zależą od kontekstu tokena.","metadata":{"tags":[],"cell_id":"40f73d3b-d9cc-478e-aebe-c87bbedc40b2"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1bc6cbd1-2646-4b7d-b54f-9eb9008dfaec"},"source":"doc = nlp(\"It costs $5.\")\nprint(\"Index:   \", [token.i for token in doc])\nprint(\"Text:    \", [token.text for token in doc])\n\nprint(\"is_alpha:\", [token.is_alpha for token in doc])\nprint(\"is_punct:\", [token.is_punct for token in doc])\nprint(\"like_num:\", [token.like_num for token in doc])","outputs":[{"name":"stdout","text":"Index:    [0, 1, 2, 3, 4]\nText:     ['It', 'costs', '$', '5', '.']\nis_alpha: [True, True, False, False, False]\nis_punct: [False, False, False, False, True]\nlike_num: [False, False, False, True, False]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Instalacja modelu języka polskiego","metadata":{"tags":[],"cell_id":"31ce4725-7b2d-4f5a-827f-ad5b9a836238"}},{"cell_type":"markdown","source":"Dokumentacja dla modelu języka polskiego znajduje się na stronie: http://spacypl.sigmoidal.io/#home\n\nInstalacja modelu:\n* Wejdź na stronę: http://zil.ipipan.waw.pl/SpacyPL\n* Pobierz arichwum z modelem o nazwie `pl_spacy_model-0.1.0.tar.gz` (kliknij w nazwę modelu, następnie `download`)\n* Dodaj plik do projektu w DeepNote, w tym celu klikaj kolejno:\n    * _Connection_\n    * _Create new Connection_\n    * _Drag and drop files here_\n    * Wybierz z dysku plik o nazwie `pl_spacy_model-0.1.0.tar.gz` i poczekaj aż się załaduje\n    * W polu _Connection name_ podaj nazwę połączenia: \"spacy_pl_model\"\n    * Submit\n    * Na liście połączeń zobaczysz nowe o nadanej przez Ciebie nazwie, przy tym połączeniu kliknij _Add_\n    * Lokalizacja nowego połączenia: `/datasets/spacy_pl_model`\n* Zainstaluj model za pomocą komendy: `!python -m pip install /datasets/spacy_pl_model/pl_spacy_model-0.1.0.tar.gz`","metadata":{"tags":[],"cell_id":"b9bc9d91-4f39-4366-8b98-cb1e4a71515a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"20c66a03-0c8c-4b77-ba33-72b234fe7465"},"source":"# Pokaż listę lokalizacji w katalogu, w którym się znajdujesz\n!ls /datasets/spacy_pl_model","outputs":[{"name":"stdout","text":"pl_spacy_model-0.1.0.tar.gz\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f1f40c92-0172-462f-9d8b-2b3b77587ab8"},"source":"!python -m pip install /datasets/spacy_pl_model/pl_spacy_model-0.1.0.tar.gz","outputs":[{"name":"stdout","text":"Processing /datasets/spacy_pl_model/pl_spacy_model-0.1.0.tar.gz\nBuilding wheels for collected packages: pl-spacy-model\n  Building wheel for pl-spacy-model (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pl-spacy-model: filename=pl_spacy_model-0.1.0-py3-none-any.whl size=170055759 sha256=55ba49e035280a152ff0fea77f2b4ead8dde5bbca14958f7c1034a8cde7321aa\n  Stored in directory: /home/jovyan/.cache/pip/wheels/47/fc/81/8b78f42f00780dd8a3976730076f93250ca98ca5babeb24a14\nSuccessfully built pl-spacy-model\nInstalling collected packages: pl-spacy-model\nSuccessfully installed pl-spacy-model-0.1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Obiekt `nlp` dla modelu języka polskiego tworzymy w następujący sposób:","metadata":{"tags":[],"cell_id":"199dd7b3-1ac2-4196-8d42-26a86e10e20a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"70c60a8e-c50f-42f7-bc92-dc9224ea72c0"},"source":"nlp = spacy.load('pl_spacy_model')","outputs":[]},{"cell_type":"markdown","source":"## Zadanie 1\n\n* Utwórz obiekt `nlp` dla modelu języka polskiego.\n* Przetwórz tekst i utwórz instancję obiektu `Doc` w zmiennej `doc`.\n* Wybierz pierwszy token obiektu `Doc` i wydrukuj jego tekst.\n\nUzupełnij luki:","metadata":{"tags":[],"cell_id":"e475f1d1-9a94-4368-af7d-c6dc0cbb0a97"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2dcead21-d5eb-4959-991c-8eb7482cffa5"},"source":"#Utwórz obiekt nlp dla modelu języka polskiego.\nnlp = spacy.____(____)\n\n# Przetwórz tekst i utwórz instancję obiektu Doc w zmiennej doc\ndoc = nlp(\"Bezbarwne zielone idee wściekle śpią.\")\n\n# Wybierz pierwszy token obiektu Doc\nfirst_token = doc[____]\n\n# Wydrukuj jego tekst\n____(first_token.____)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Wytnij następujące fragmenty tekstu:\n    * `\"Bezbarwne zielone\"`\n    * `\"zielone idee\"`\n    * `\"idee wściekle śpią\"` (zwróć uwagę na brak kropki)\n* przypisz je do kolejnych zmiennych `slice_1`, `slice_2`, `slice_3`","metadata":{"tags":[],"cell_id":"a2a0668b-0f07-452b-9734-01d42c769525"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"65d2631c-d2e3-4961-ae65-39b825c7ccfa"},"source":"# \"Bezbarwne zielone\"\nslice_1 = ____\nprint(slice_1.text)","outputs":[{"output_type":"error","ename":"NameError","evalue":"name '____' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-ca90f13cdcb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \"Bezbarwne zielone\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslice_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_kangaroos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '____' is not defined"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"16ee5dbd-644a-4103-81a6-f91b9dd6d291"},"source":"# \"zielone idee\"\nslice_2 = ____\nprint(slice_2.text)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0d321c19-ceea-418f-9845-883b5cd1c346"},"source":"# \"idee wściekle śpią\"\nslice_3 = ____\nprint(slice_3.text)","outputs":[{"output_type":"error","ename":"NameError","evalue":"name '____' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-dd72804a6ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \"idee wściekle śpią\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslice_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '____' is not defined"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"bacd0c47-ad6f-4ea8-80c1-fc408484890c"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## New markdown cell","metadata":{"tags":[],"cell_id":"ea67c97e-9d2a-4cc9-a111-f475e2d186d7"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_notebook_id":"cd90b28b-d574-4aae-8dec-61b1b7a67319","deepnote_execution_queue":[]}}